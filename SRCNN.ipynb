{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.4 |Continuum Analytics, Inc.| (default, Aug 14 2017, 13:26:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Keras: 1.2.2\n",
      "OpenCV: 3.3.0\n",
      "NumPy: 1.13.1\n",
      "Matplotlib: 2.0.2\n",
      "Scikit-Image: 0.13.1\n"
     ]
    }
   ],
   "source": [
    "# check package versions\n",
    "import sys\n",
    "import keras\n",
    "import cv2\n",
    "import numpy\n",
    "import matplotlib\n",
    "import skimage\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Keras: {}'.format(keras.__version__))\n",
    "print('OpenCV: {}'.format(cv2.__version__))\n",
    "print('NumPy: {}'.format(numpy.__version__))\n",
    "print('Matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('Scikit-Image: {}'.format(skimage.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# python magic function, displays pyplot figures in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for peak signal-to-noise ratio (PSNR)\n",
    "def psnr(target, ref):\n",
    "         \n",
    "    # assume RGB image\n",
    "    target_data = target.astype(float)\n",
    "    ref_data = ref.astype(float)\n",
    "\n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')\n",
    "\n",
    "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
    "\n",
    "    return 20 * math.log10(255. / rmse)\n",
    "\n",
    "# define function for mean squared error (MSE)\n",
    "def mse(target, ref):\n",
    "    # the MSE between the two images is the sum of the squared difference between the two images\n",
    "    err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
    "    err /= float(target.shape[0] * target.shape[1])\n",
    "    \n",
    "    return err\n",
    "\n",
    "# define function that combines all three image quality metrics\n",
    "def compare_images(target, ref):\n",
    "    scores = []\n",
    "    scores.append(psnr(target, ref))\n",
    "    scores.append(mse(target, ref))\n",
    "    scores.append(ssim(target, ref, multichannel =True))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =5 \n",
    "b =2\n",
    "c=1\n",
    "c/=b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images(path,factor):\n",
    "    for file in os.listdir(path):\n",
    "        img=cv2.imread(path +'/'+file)\n",
    "\n",
    "        \n",
    "        #find old and new image dimenstions\n",
    "        h,w,c = img.shape\n",
    "        new_height = int(h/factor)\n",
    "        new_width = int(w/factor)\n",
    "        \n",
    "        #resize the image - down\n",
    "        img = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_LINEAR)        \n",
    "        #Different types of interpolation kernel - bilinear, nearest neighbour, bicubic\n",
    "        # resize image back up\n",
    "        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        print('Saving {}'.format(file))\n",
    "        cv2.imwrite ('imagessource/{}'.format(file),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test5\n"
     ]
    }
   ],
   "source": [
    "print ('test{}'.format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving lenna.bmp\n",
      "Saving pepper.bmp\n",
      "Saving comic.bmp\n",
      "Saving head_GT.bmp\n",
      "Saving butterfly_GT.bmp\n",
      "Saving foreman.bmp\n",
      "Saving ppt3.bmp\n",
      "Saving woman_GT.bmp\n",
      "Saving baby_GT.bmp\n",
      "Saving bird_GT.bmp\n",
      "Saving zebra.bmp\n",
      "Saving flowers.bmp\n",
      "Saving monarch.bmp\n",
      "Saving face.bmp\n",
      "Saving baboon.bmp\n",
      "Saving barbara.bmp\n",
      "Saving coastguard.bmp\n"
     ]
    }
   ],
   "source": [
    "prepare_images('source/',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenna.bmp\n",
      "PSNR: 31.47349297867539\n",
      "MSE: 138.94800567626953\n",
      "SSIM: 0.8460989200521359\n",
      "\n",
      "pepper.bmp\n",
      "PSNR: 29.88947161686106\n",
      "MSE: 200.1033935546875\n",
      "SSIM: 0.8357937568464591\n",
      "\n",
      "comic.bmp\n",
      "PSNR: 23.799861502225532\n",
      "MSE: 813.2338836565096\n",
      "SSIM: 0.8347335416398346\n",
      "\n",
      "head_GT.bmp\n",
      "PSNR: 31.020502848237534\n",
      "MSE: 154.2237755102041\n",
      "SSIM: 0.8011121330733427\n",
      "\n",
      "butterfly_GT.bmp\n",
      "PSNR: 24.782076560337416\n",
      "MSE: 648.6254119873047\n",
      "SSIM: 0.8791344763843071\n",
      "\n",
      "foreman.bmp\n",
      "PSNR: 30.14456532664372\n",
      "MSE: 188.6883483270202\n",
      "SSIM: 0.9332684173888618\n",
      "\n",
      "ppt3.bmp\n",
      "PSNR: 24.84926168950471\n",
      "MSE: 638.6684263912582\n",
      "SSIM: 0.9284023942317523\n",
      "\n",
      "woman_GT.bmp\n",
      "PSNR: 29.326236280817465\n",
      "MSE: 227.812729498164\n",
      "SSIM: 0.9335397280466554\n",
      "\n",
      "baby_GT.bmp\n",
      "PSNR: 34.371806409661986\n",
      "MSE: 71.28874588012695\n",
      "SSIM: 0.9356987872724792\n",
      "\n",
      "bird_GT.bmp\n",
      "PSNR: 32.896644728720005\n",
      "MSE: 100.12375819830247\n",
      "SSIM: 0.9533644866026506\n",
      "\n",
      "zebra.bmp\n",
      "PSNR: 27.909840639329513\n",
      "MSE: 315.6585459528818\n",
      "SSIM: 0.8911656209329136\n",
      "\n",
      "flowers.bmp\n",
      "PSNR: 27.454504805386144\n",
      "MSE: 350.55093922651935\n",
      "SSIM: 0.86972862869746\n",
      "\n",
      "monarch.bmp\n",
      "PSNR: 30.196242365288896\n",
      "MSE: 186.45643615722656\n",
      "SSIM: 0.9439574293434231\n",
      "\n",
      "face.bmp\n",
      "PSNR: 30.99220650287191\n",
      "MSE: 155.23189718546524\n",
      "SSIM: 0.8008439492289946\n",
      "\n",
      "baboon.bmp\n",
      "PSNR: 22.157084083442548\n",
      "MSE: 1187.1161333333334\n",
      "SSIM: 0.6292775879002784\n",
      "\n",
      "barbara.bmp\n",
      "PSNR: 25.906629837568126\n",
      "MSE: 500.65508535879627\n",
      "SSIM: 0.8098632646406436\n",
      "\n",
      "coastguard.bmp\n",
      "PSNR: 27.161600663887082\n",
      "MSE: 375.00887784090907\n",
      "SSIM: 0.7569500633549281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the generated images using the image quality metrics\n",
    "\n",
    "for file in os.listdir('imagessource/'):\n",
    "    \n",
    "    # open target and reference images\n",
    "    target = cv2.imread('imagessource/{}'.format(file))\n",
    "    ref = cv2.imread('source/{}'.format(file))\n",
    "    \n",
    "    # calculate score\n",
    "    scores = compare_images(target, ref)\n",
    "\n",
    "    # print all three scores with new line characters (\\n) \n",
    "    print('{}\\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(file, scores[0], scores[1], scores[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lenna.bmp\n",
    "PSNR: 31.47349297867539 # higher the better \n",
    "MSE: 138.94800567626953 # higher means lower resolution\n",
    "SSIM: 0.8460989200521359 # 1 means better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the SRCNN model\n",
    "def model():\n",
    "    \n",
    "    # define model type\n",
    "    SRCNN = Sequential()\n",
    "    \n",
    "    # add model layers\n",
    "    SRCNN.add(Conv2D(128, 9,9,activation='relu',init='normal',input_shape=(None, None, 1)))\n",
    "    SRCNN.add(Conv2D(64, 3, 3,activation='relu', init='normal'))\n",
    "    SRCNN.add(Conv2D(1, 5, 5,activation='linear', init='normal'))\n",
    "    \n",
    "    # define optimizer\n",
    "    adam = Adam(lr=0.0003)\n",
    "    \n",
    "    # compile model\n",
    "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/nj/Downloads/srcnn_weights.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary image processing functions\n",
    "\n",
    "def modcrop(img, scale):\n",
    "    tmpsz = img.shape\n",
    "    sz = tmpsz[0:2]\n",
    "    sz = sz - np.mod(sz, scale)\n",
    "    img = img[0:sz[0], 1:sz[1]]\n",
    "    return img\n",
    "\n",
    "\n",
    "def shave(image, border):\n",
    "    img = image[border: -border, border: -border]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main prediction function\n",
    "\n",
    "def predict(image_path):\n",
    "    \n",
    "    # load the srcnn model with weights\n",
    "    srcnn = model()\n",
    "    srcnn.load_weights('')\n",
    "    \n",
    "    # load the degraded and reference images\n",
    "    path, file = os.path.split(image_path)\n",
    "    degraded = cv2.imread(image_path)\n",
    "    ref = cv2.imread('source/{}'.format(file))\n",
    "    \n",
    "    # preprocess the image with modcrop\n",
    "    ref = modcrop(ref, 3)\n",
    "    degraded = modcrop(degraded, 3)\n",
    "    \n",
    "    # convert the image to YCrCb - (srcnn trained on Y channel)\n",
    "    temp = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # create image slice and normalize  \n",
    "    Y = numpy.zeros((1, temp.shape[0], temp.shape[1], 1), dtype=float)\n",
    "    Y[0, :, :, 0] = temp[:, :, 0].astype(float) / 255\n",
    "    \n",
    "    # perform super-resolution with srcnn\n",
    "    pre = srcnn.predict(Y, batch_size=1)\n",
    "    \n",
    "    # post-process output\n",
    "    pre *= 255\n",
    "    pre[pre[:] > 255] = 255\n",
    "    pre[pre[:] < 0] = 0\n",
    "    pre = pre.astype(np.uint8)\n",
    "    \n",
    "    # copy Y channel back to image and convert to BGR\n",
    "    temp = shave(temp, 6)\n",
    "    temp[:, :, 0] = pre[0, :, :, 0]\n",
    "    output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    # remove border from reference and degraged image\n",
    "    ref = shave(ref.astype(np.uint8), 6)\n",
    "    degraded = shave(degraded.astype(np.uint8), 6)\n",
    "    \n",
    "    # image quality calculations\n",
    "    scores = []\n",
    "    scores.append(compare_images(degraded, ref))\n",
    "    scores.append(compare_images(output, ref))\n",
    "    \n",
    "    # return images and scores\n",
    "    return ref, degraded, output, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-2c1fcb4259fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegraded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/flowers.bmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print all scores for all images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Degraded Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reconstructed Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-132-43c4eba0b9b2>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# copy Y channel back to image and convert to BGR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "ref, degraded, output, scores = predict('images/flowers.bmp')\n",
    "\n",
    "# print all scores for all images\n",
    "print('Degraded Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[0][0], scores[0][1], scores[0][2]))\n",
    "print('Reconstructed Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[1][0], scores[1][1], scores[1][2]))\n",
    "\n",
    "\n",
    "# display images as subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
    "axs[0].set_title('Original')\n",
    "axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title('Degraded')\n",
    "axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "axs[2].set_title('SRCNN')\n",
    "\n",
    "# remove the x and y ticks\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ValueError: could not broadcast input array from shape (346,483) into shape (348,485)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfdeeplearning]",
   "language": "python",
   "name": "conda-env-tfdeeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
